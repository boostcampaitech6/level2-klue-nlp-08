train_config:
    model_name: vaiv/kobigbird-roberta-large  # 사전 훈련된 모델 이름
    model_save_name: vaiv/kobigbird-roberta-large-focal-none-10-v2 # wandb 사용 시 wandb.init 의 name 인자에 대한 값으로 보내는 용도입니다.
    add_query: False # TypedEntityMarkerPuncTokenizer 에서 add_query 사용할지 여부
    train_dataset_path: ./dataset/train/train_split_v2.csv  # 훈련 데이터셋 파일 위치
    valid_dataset_path: ./dataset/train/valid_split_v1.csv # 평가 데이터셋 파일 위치
    tokenizer_type: TypedEntityMarkerPuncTokenizer  # TypedEntityMarkerPuncTokenizer, TypedEntityMarkerTokenizer, ConcatEntityTokenizer

train_args:
    output_dir: ./results/vaiv/kobigbird-roberta-large-focal-none-10-v2  # 출력 디렉토리
    save_total_limit: 1  # 저장된 총 모델 수 제한
    save_steps: 500  # 모델 저장 간격
    num_train_epochs: 10  # 총 훈련 에폭 수
    learning_rate: 0.00005  # 학습률
    per_device_train_batch_size: 64  # 훈련 중 각 장치당 배치 크기
    per_device_eval_batch_size: 64  # 평가용 배치 크기
    warmup_steps: 500  # 학습률 스케줄러의 워머업 스텝 수
    weight_decay: 0.05  # 가중치 감소의 강도
    logging_dir: ./logs  # 로그 저장 디렉토리
    logging_steps: 100  # 로그 저장 간격
    evaluation_strategy: steps  # 훈련 중 채택할 평가 전략
    eval_steps: 100  # 평가 간격
    load_best_model_at_end: True  # 훈련 종료 시 최상의 모델 로드 여부
    metric_for_best_model: micro f1 score